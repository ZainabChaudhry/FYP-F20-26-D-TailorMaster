{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMBsCRUZeYyTcKioZppDJxo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmnyOzAm2ipG","executionInfo":{"status":"ok","timestamp":1608639131267,"user_tz":-300,"elapsed":28926,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"3a13d041-76af-414a-dada-817b177a2d15"},"source":["import cv2\r\n","from google.colab import drive\r\n","\r\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzRJUj4SBnCO","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1608517744259,"user_tz":-300,"elapsed":14430,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"e9326242-4e5f-44e7-b917-62b1bfda3b8a"},"source":["!pip install tf-bodypix[all]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tf-bodypix[all]\n","  Downloading https://files.pythonhosted.org/packages/41/99/c2ef8fb2f0103e1da6acc6c9a3d0e9720ca7b9170fb12a89c64cf310192c/tf_bodypix-0.3.4-py3-none-any.whl\n","Collecting Pillow==8.0.1; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 11.9MB/s \n","\u001b[?25hCollecting tfjs-graph-converter==1.4.2; extra == \"all\"\n","  Downloading https://files.pythonhosted.org/packages/0c/89/b148baab02f490aad9be57a917e7dee664552ed68fe225da8ede51af81e8/tfjs_graph_converter-1.4.2-py3-none-any.whl\n","Collecting opencv-python==4.4.0.46; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/80/10a9ae6fa0940f25af32739d1dc6dfdbbdc79af3f04c5ea1a6de4303cd54/opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5MB)\n","\u001b[K     |████████████████████████████████| 49.5MB 65kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow==2.4.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tf-bodypix[all]) (2.4.0)\n","Collecting pyfakewebcam==0.1.0; extra == \"all\"\n","  Downloading https://files.pythonhosted.org/packages/ce/8b/0bb1984cf716d7b4825a1480f77e71441d39ffebb158ccce5e95ce17eec9/pyfakewebcam-0.1.0.tar.gz\n","Collecting tensorflowjs>=1.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/7e/b005271236ddb90fb8a85e29e32ba0841e6737faf9068adbc5ca28df6a41/tensorflowjs-2.8.1-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 12.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==4.4.0.46; extra == \"all\"->tf-bodypix[all]) (1.19.4)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.10.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2.4.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.36.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.12.4)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.1.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.1.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.3.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2.10.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.12.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.3.3)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2.4.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.15.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.32.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.12)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.2.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.7.4.3)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.6.3)\n","Collecting tensorflow-hub<0.10,>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 37.8MB/s \n","\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.3.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (50.3.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.7.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (4.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (4.6)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0; extra == \"all\"->tf-bodypix[all]) (3.4.0)\n","Building wheels for collected packages: pyfakewebcam\n","  Building wheel for pyfakewebcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyfakewebcam: filename=pyfakewebcam-0.1.0-cp36-none-any.whl size=12671 sha256=c476005fb29f0b15181873e360061d631a22ed168cae634346b1243022ec940a\n","  Stored in directory: /root/.cache/pip/wheels/f9/f5/02/bce72cbe64394c0eac46cabc66a04e45370b78cb4d1704e5a0\n","Successfully built pyfakewebcam\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: Pillow, tensorflow-hub, tensorflowjs, tfjs-graph-converter, opencv-python, pyfakewebcam, tf-bodypix\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: tensorflow-hub 0.10.0\n","    Uninstalling tensorflow-hub-0.10.0:\n","      Successfully uninstalled tensorflow-hub-0.10.0\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","Successfully installed Pillow-8.0.1 opencv-python-4.4.0.46 pyfakewebcam-0.1.0 tensorflow-hub-0.9.0 tensorflowjs-2.8.1 tf-bodypix-0.3.4 tfjs-graph-converter-1.4.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","cv2"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5X9dqpFs85dZ","executionInfo":{"status":"ok","timestamp":1608639178097,"user_tz":-300,"elapsed":3867,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"6ca6ad5c-77cd-4f03-be16-0e6d0b52203f"},"source":["!git clone https://github.com/misbah4064/human-pose-estimation-opencv.git\r\n","%cd human-pose-estimation-opencv/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'human-pose-estimation-opencv'...\n","remote: Enumerating objects: 20, done.\u001b[K\n","remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20\u001b[K\n","Unpacking objects: 100% (20/20), done.\n","/content/human-pose-estimation-opencv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L2XYpmunvn9s","executionInfo":{"status":"ok","timestamp":1608639182000,"user_tz":-300,"elapsed":2072,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["import cv2\r\n","import string\r\n","def getFrames(path):\r\n","  vidcap = cv2.VideoCapture(path)\r\n","  count = 0\r\n","  success = True\r\n","  fps = int(vidcap.get(cv2.CAP_PROP_FPS))\r\n","  i=1\r\n","  im=0\r\n","  imagepaths=[]\r\n","  tempstr=\"\"\r\n","  while success:\r\n","    success,image = vidcap.read()\r\n","    print('read a new frame:',success)\r\n","    if count%(i*fps) == 0 :\r\n","      if (len(image)<len(image[0])):\r\n","        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\r\n","      tempstr=\"/content/drive/My Drive/FYP/img\"+str(im)+\".jpg\"\r\n","      cv2.imwrite(\"/content/drive/My Drive/FYP/img\"+str(im)+\".jpg\",image)\r\n","      imagepaths.append(tempstr)\r\n","      print('successful')\r\n","      im+=1\r\n","      i+=3\r\n","    count+=1\r\n","  return imagepaths"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAqDhag7lREr","executionInfo":{"status":"ok","timestamp":1608639190577,"user_tz":-300,"elapsed":1989,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["pixelMeasurementsCheck={\"ShoulderLength\":0,\"EyetoAnkle\":1,\"ShirtLength\":2,\"ShalwarLength\":3,\"ArmsLength\":4,\"ChestCircum\":5,\"WasteCircum\":6,\"BackCircum\":7}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZiVSqfqjRlG","executionInfo":{"status":"ok","timestamp":1608639194883,"user_tz":-300,"elapsed":2980,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getShoulderLength(pointsInFrame):\r\n","  shoulderLength=0\r\n","  if (pointsInFrame[2]!=None):\r\n","    if pointsInFrame[5]!=None:\r\n","      shoulderLength=abs(pointsInFrame[2][0]-pointsInFrame[5][0])\r\n","    elif pointsInFrame[1]!=None:\r\n","      shoulderLength=abs(pointsInFrame[2][0]-pointsInFrame[1][0])*2\r\n","    elif pointsInFrame[20]!=None:\r\n","      shoulderLength=abs(pointsInFrame[2][0]-pointsInFrame[20][0])*2\r\n","  elif pointsInFrame[5]!=None:\r\n","    if pointsInFrame[1]!=None:\r\n","      shoulderLength=abs(pointsInFrame[5][0]-pointsInFrame[1][0])*2\r\n","    elif pointsInFrame[20]!=None:\r\n","      shoulderLength=abs(pointsInFrame[5][0]-pointsInFrame[20][0])*2\r\n","  return shoulderLength"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2efcJQ0nsHX","executionInfo":{"status":"ok","timestamp":1608639200988,"user_tz":-300,"elapsed":1440,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getEyeToAnkle(pointsInFrame):\r\n","  EyeToAnkleLength=0\r\n","  if (pointsInFrame[14]!=None):\r\n","    if pointsInFrame[10]!=None and pointsInFrame[13]!=None:\r\n","      if (pointsInFrame[10][1]>pointsInFrame[13][1]):\r\n","        EyeToAnkleLength=abs(pointsInFrame[10][1]-pointsInFrame[14][1])\r\n","      else:\r\n","        EyeToAnkleLength=abs(pointsInFrame[13][1]-pointsInFrame[14][1])\r\n","    elif pointsInFrame[10]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[10][1]-pointsInFrame[14][1])\r\n","    elif pointsInFrame[13]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[14][1]-pointsInFrame[13][1])\r\n","    elif pointsInFrame[29]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[14][1]-pointsInFrame[29][1])\r\n","    elif pointsInFrame[30]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[14][1]-pointsInFrame[30][1])+15\r\n","    elif pointsInFrame[24]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[24][1]-pointsInFrame[14][1])+15\r\n","  elif pointsInFrame[15]!=None:\r\n","    if pointsInFrame[10]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[10][1]-pointsInFrame[15][1])\r\n","    elif pointsInFrame[13]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[15][1]-pointsInFrame[13][1])\r\n","    elif pointsInFrame[29]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[15][1]-pointsInFrame[29][1])\r\n","    elif pointsInFrame[30]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[15][1]-pointsInFrame[30][1])+15\r\n","    elif pointsInFrame[24]!=None:\r\n","      EyeToAnkleLength=abs(pointsInFrame[24][1]-pointsInFrame[15][1])+15\r\n","  return EyeToAnkleLength"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9p0Jn3uPv5J3","executionInfo":{"status":"ok","timestamp":1608639208253,"user_tz":-300,"elapsed":1581,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getShirtLength(pointsInFrame):\r\n","  ShirtLength=0\r\n","  if (pointsInFrame[2]!=None):\r\n","    if pointsInFrame[9]!=None:\r\n","      if (pointsInFrame[9][1]<pointsInFrame[10][1]):\r\n","        ShirtLength=abs(pointsInFrame[2][1]-pointsInFrame[9][1])\r\n","    elif pointsInFrame[12]!=None:\r\n","      ShirtLength=abs(pointsInFrame[2][1]-pointsInFrame[12][1])\r\n","    elif pointsInFrame[22]!=None:\r\n","      ShirtLength=abs(pointsInFrame[22][1]-pointsInFrame[2][1])+20\r\n","    elif pointsInFrame[28]!=None:\r\n","      ShirtLength=abs(pointsInFrame[2][1]-pointsInFrame[28][1])+20\r\n","    elif pointsInFrame[8]!=None:\r\n","      ShirtLength=abs(pointsInFrame[2][1]-pointsInFrame[8][1])*1.5\r\n","    elif pointsInFrame[11]!=None:\r\n","      ShirtLength=abs(pointsInFrame[2][1]-pointsInFrame[11][1])*1.5\r\n","  elif pointsInFrame[5]!=None:\r\n","    if pointsInFrame[9]!=None:\r\n","      ShirtLength=abs(pointsInFrame[5][1]-pointsInFrame[9][1])\r\n","    elif pointsInFrame[12]!=None:\r\n","      ShirtLength=abs(pointsInFrame[5][1]-pointsInFrame[12][1])\r\n","    elif pointsInFrame[22]!=None:\r\n","      ShirtLength=abs(pointsInFrame[22][1]-pointsInFrame[5][1])+20\r\n","    elif pointsInFrame[28]!=None:\r\n","      ShirtLength=abs(pointsInFrame[5][1]-pointsInFrame[28][1])+20\r\n","    elif pointsInFrame[8]!=None:\r\n","      ShirtLength=abs(pointsInFrame[5][1]-pointsInFrame[8][1])*1.5\r\n","    elif pointsInFrame[11]!=None:\r\n","      ShirtLength=abs(pointsInFrame[5][1]-pointsInFrame[11][1])*1.5\r\n","  print(ShirtLength)\r\n","  return ShirtLength"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVcgnl-pEwxW","executionInfo":{"status":"ok","timestamp":1608639255166,"user_tz":-300,"elapsed":1202,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getShalwarLength(pointsInFrame):\r\n","  ShalwarLength=0\r\n","  if (pointsInFrame[8]!=None):\r\n","    if pointsInFrame[10]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[8][1]-pointsInFrame[10][1])\r\n","    elif pointsInFrame[13]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[8][1]-pointsInFrame[13][1])\r\n","    elif pointsInFrame[29]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[8][1]-pointsInFrame[29][1])\r\n","    elif pointsInFrame[30]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[8][1]-pointsInFrame[30][1])+20\r\n","    elif pointsInFrame[24]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[8][1]-pointsInFrame[24][1])+20\r\n","  elif pointsInFrame[11]!=None:\r\n","    if pointsInFrame[10]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[11][1]-pointsInFrame[10][1])\r\n","    elif pointsInFrame[13]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[11][1]-pointsInFrame[13][1])\r\n","    elif pointsInFrame[29]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[11][1]-pointsInFrame[29][1])\r\n","    elif pointsInFrame[30]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[11][1]-pointsInFrame[30][1])+20\r\n","    elif pointsInFrame[24]!=None:\r\n","      ShalwarLength=abs(pointsInFrame[11][1]-pointsInFrame[24][1])+20\r\n","  return ShalwarLength"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"xynpE9MFMjwY","executionInfo":{"status":"ok","timestamp":1608639262888,"user_tz":-300,"elapsed":1262,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getArmLength(pointsInFrame,frame):\r\n","  ArmLength=0\r\n","  if frame==0:\r\n","    if (pointsInFrame[2]!=None and pointsInFrame[4]!=None and pointsInFrame[2][0]>pointsInFrame[4][0]):\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[4][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[4][1])**2))\r\n","    elif (pointsInFrame[5]!=None and pointsInFrame[7]!=None and pointsInFrame[5][0]<pointsInFrame[7][0]):\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[7][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[7][1])**2))\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[7]!=None and pointsInFrame[2][0]>pointsInFrame[7][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[7][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[7][1])**2))\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[4]!=None and pointsInFrame[5][0]<pointsInFrame[4][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[4][0]-pointsInFrame[5][0])**2)+(abs(pointsInFrame[4][1]-pointsInFrame[5][1])**2))\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[3]!=None and pointsInFrame[2][0]>pointsInFrame[3][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[3][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[3][1])**2))*2\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[6]!=None and pointsInFrame[5][0]<pointsInFrame[6][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[6][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[6][1])**2))*2\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[6]!=None and pointsInFrame[2][0]>pointsInFrame[6][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[6][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[6][1])**2))*2\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[3]!=None and pointsInFrame[5][0]<pointsInFrame[3][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[3][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[3][1])**2))*2\r\n","  elif frame==2:\r\n","    if (pointsInFrame[2]!=None and pointsInFrame[4]!=None and pointsInFrame[2][0]<pointsInFrame[4][0]):\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[4][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[4][1])**2))\r\n","    elif (pointsInFrame[5]!=None and pointsInFrame[7]!=None and pointsInFrame[5][0]>pointsInFrame[7][0]):\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[7][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[7][1])**2))\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[7]!=None and pointsInFrame[2][0]<pointsInFrame[7][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[7][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[7][1])**2))\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[4]!=None and pointsInFrame[5][0]>pointsInFrame[4][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[4][0]-pointsInFrame[5][0])**2)+(abs(pointsInFrame[4][1]-pointsInFrame[5][1])**2))\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[3]!=None and pointsInFrame[2][0]<pointsInFrame[3][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[3][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[3][1])**2))*2\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[6]!=None and pointsInFrame[5][0]>pointsInFrame[6][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[6][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[6][1])**2))*2\r\n","    elif pointsInFrame[2]!=None and pointsInFrame[6]!=None and pointsInFrame[2][0]<pointsInFrame[6][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[2][0]-pointsInFrame[6][0])**2)+(abs(pointsInFrame[2][1]-pointsInFrame[6][1])**2))*2\r\n","    elif pointsInFrame[5]!=None and pointsInFrame[3]!=None and pointsInFrame[5][0]>pointsInFrame[3][0]:\r\n","      ArmLength=np.sqrt((abs(pointsInFrame[5][0]-pointsInFrame[3][0])**2)+(abs(pointsInFrame[5][1]-pointsInFrame[3][1])**2))*2\r\n","  return ArmLength"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"COm_FpYkeXR8","executionInfo":{"status":"ok","timestamp":1608639269359,"user_tz":-300,"elapsed":651,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getChestCircum(pointsInFrame):\r\n","  ChestCircum=0\r\n","  if (pointsInFrame[33]!=None and pointsInFrame[41]!=None):\r\n","    ChestCircum=abs(pointsInFrame[33][0]-pointsInFrame[41][0])*2.8\r\n","  elif pointsInFrame[33]!=None and pointsInFrame[20]!=None:\r\n","    ChestCircum=abs(pointsInFrame[33][0]-pointsInFrame[20][0])*4.8\r\n","  elif pointsInFrame[41]!=None and pointsInFrame[20]!=None:\r\n","    ChestCircum=abs(pointsInFrame[20][0]-pointsInFrame[41][0])*4.8\r\n","  elif pointsInFrame[41]!=None and pointsInFrame[26]!=None:\r\n","    ChestCircum=abs(pointsInFrame[26][0]-pointsInFrame[41][0])*4.8\r\n","  elif pointsInFrame[33]!=None and pointsInFrame[26]!=None:\r\n","    ChestCircum=abs(pointsInFrame[26][0]-pointsInFrame[33][0])*4.8\r\n","  return ChestCircum"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"clhB9rqRr2hd","executionInfo":{"status":"ok","timestamp":1608639275366,"user_tz":-300,"elapsed":1166,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getWaistCircum(pointsInFrame):\r\n","  WaistCircum=0\r\n","  if (pointsInFrame[8]!=None and pointsInFrame[11]!=None):\r\n","    WaistCircum=abs(pointsInFrame[8][0]-pointsInFrame[11][0])*4.6\r\n","  elif pointsInFrame[8]!=None and pointsInFrame[28]!=None:\r\n","    WaistCircum=abs(pointsInFrame[8][0]-pointsInFrame[28][0])*4.6\r\n","  elif pointsInFrame[11]!=None and pointsInFrame[22]!=None:\r\n","    WaistCircum=abs(pointsInFrame[22][0]-pointsInFrame[11][0])*4.6\r\n","  return WaistCircum"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVnMKTZsOVGi","executionInfo":{"status":"ok","timestamp":1608639278079,"user_tz":-300,"elapsed":1202,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def getBackCircum(pointsInFrame):\r\n","  BackCircum=0\r\n","  if (pointsInFrame[19]!=None and pointsInFrame[25]!=None):\r\n","    BackCircum=abs(pointsInFrame[19][0]-pointsInFrame[25][0])*4\r\n","  elif pointsInFrame[41]!=None and pointsInFrame[20]!=None:\r\n","    BackCircum=abs(pointsInFrame[41][0]-pointsInFrame[20][0])*4\r\n","  elif pointsInFrame[33]!=None and pointsInFrame[20]!=None:\r\n","    BackCircum=abs(pointsInFrame[20][0]-pointsInFrame[33][0])*4\r\n","  elif pointsInFrame[8]!=None and pointsInFrame[11]!=None:\r\n","    BackCircum=abs(pointsInFrame[8][0]-pointsInFrame[11][0])*4\r\n","  elif pointsInFrame[33]!=None and pointsInFrame[26]!=None:\r\n","    BackCircum=abs(pointsInFrame[26][0]-pointsInFrame[33][0])*4\r\n","  elif pointsInFrame[41]!=None and pointsInFrame[26]!=None:\r\n","    BackCircum=abs(pointsInFrame[41][0]-pointsInFrame[26][0])*4\r\n","  return BackCircum\r\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIjJcIMlUytQ","executionInfo":{"status":"ok","timestamp":1608639285026,"user_tz":-300,"elapsed":1281,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["def GetMeasurementsInPixels(pointsInFrame,CheckList,measurements,frame,health,gender):\r\n","  if (CheckList[0]==False):\r\n","    measurements[0]=getShoulderLength(pointsInFrame)\r\n","    if (measurements[0]>0):\r\n","      CheckList[0]=True\r\n","  if (CheckList[1]==False):\r\n","    measurements[1]=getEyeToAnkle(pointsInFrame)\r\n","    if (measurements[1]>0):\r\n","      CheckList[1]=True\r\n","  if (CheckList[2]==False):\r\n","    shirtLength=getShirtLength(pointsInFrame)\r\n","    if shirtLength>0 and shirtLength<measurements[1]:\r\n","      measurements[2]=shirtLength\r\n","      CheckList[2]=True\r\n","  if (CheckList[3]==False):\r\n","    measurements[3]=getShalwarLength(pointsInFrame)\r\n","    if measurements[3]>0:\r\n","      CheckList[3]=True\r\n","  if (CheckList[4]==False):\r\n","    measurements[4]=getArmLength(pointsInFrame,frame)\r\n","    if measurements[4]>0:\r\n","      CheckList[4]=True\r\n","  if (CheckList[5]==False):\r\n","    measurements[5]=getChestCircum(pointsInFrame)\r\n","    if measurements[5]>0:\r\n","      CheckList[5]=True\r\n","  if (CheckList[6]==False):\r\n","    measurements[6]=getWaistCircum(pointsInFrame)\r\n","    if measurements[6]>0:\r\n","      CheckList[6]=True\r\n","  if (CheckList[7]==False):\r\n","    measurements[7]=getBackCircum(pointsInFrame)\r\n","    if measurements[7]>0:\r\n","      CheckList[7]=True\r\n","  if frame>0:\r\n","    if getShoulderLength(pointsInFrame)>measurements[0] and getShoulderLength(pointsInFrame)<measurements[1]:\r\n","      measurements[0]=getShoulderLength(pointsInFrame)\r\n","    if getShalwarLength(pointsInFrame)>measurements[3] and getShirtLength(pointsInFrame)<measurements[1]:\r\n","      measurements[3]=getShalwarLength(pointsInFrame)\r\n","  if frame>=3:\r\n","    if (gender==\"male\"):\r\n","      if measurements[2]==0 or measurements[2]>(0.65*measurements[1]) or measurements[3]<(.6*measurements[1]):\r\n","        measurements[2]=measurements[1]*0.62\r\n","      if measurements[3]==0 or measurements[3]>(.58*measurements[1]) or measurements[3]<(.54*measurements[1]):\r\n","        measurements[3]=measurements[1]*0.57\r\n","      if measurements[0]==0 or measurements[0]>(.29*measurements[1]) or measurements[0]<(.25*measurements[1]):\r\n","        measurements[0]=measurements[1]*0.27\r\n","      if (health==\"normal\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.59) or measurements[5]<(measurements[1]*0.55):\r\n","          measurements[5]=measurements[1]*.57\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.58) or measurements[6]<(measurements[1]*.55):\r\n","          measurements[6]=measurements[1]*.56\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.57) or measurements[7]<(measurements[1]*.52):\r\n","          measurements[7]=measurements[1]*.55\r\n","      if (health==\"healthy\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.64) or measurements[5]<(measurements[1]*0.6):\r\n","          measurements[5]=measurements[1]*.62\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.67) or measurements[6]<(measurements[1]*.62):\r\n","          measurements[6]=measurements[1]*.64\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.61) or measurements[7]<(measurements[1]*.56):\r\n","          measurements[7]=measurements[1]*.55\r\n","      if (health==\"slim\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.59) or measurements[5]<(measurements[1]*0.55):\r\n","          measurements[5]=measurements[1]*.57\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.55) or measurements[6]<(measurements[1]*.52):\r\n","          measurements[6]=measurements[1]*.54\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.58) or measurements[7]<(measurements[1]*.54):\r\n","          measurements[7]=measurements[1]*.52\r\n","      if (health==\"bulky\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.60) or measurements[5]<(measurements[1]*0.65):\r\n","          measurements[5]=measurements[1]*.63\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.7) or measurements[6]<(measurements[1]*.57):\r\n","          measurements[6]=measurements[1]*.69\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.65) or measurements[7]<(measurements[1]*.62):\r\n","          measurements[7]=measurements[1]*.64\r\n","    if (gender==\"female\"):\r\n","      if measurements[2]==0 or measurements[2]>(0.59*measurements[1]) or measurements[3]<(.55*measurements[1]):\r\n","        measurements[2]=measurements[1]*0.57\r\n","      if measurements[3]==0 or measurements[3]>(.57*measurements[1]) or measurements[3]<(.52*measurements[1]):\r\n","        measurements[3]=measurements[1]*0.55\r\n","      if measurements[0]==0 or measurements[0]>(.27*measurements[1]) or measurements[0]<(.24*measurements[1]):\r\n","        measurements[0]=measurements[1]*0.25\r\n","      if measurements[4]==0 or measurements[4]>(.32*measurements[1]) or measurements[0]<(.30*measurements[1]):\r\n","        measurements[4]=measurements[1]*.32\r\n","      if (health==\"normal\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.58) or measurements[5]<(measurements[1]*0.55):\r\n","          measurements[5]=measurements[1]*.56\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.56) or measurements[6]<(measurements[1]*.52):\r\n","          measurements[6]=measurements[1]*.54\r\n","        if measurements[6]==0 or measurements[7]>(measurements[1]*.52) or measurements[6]<(measurements[1]*.49):\r\n","          measurements[6]=measurements[1]*.51\r\n","      if (health==\"healthy\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.60) or measurements[5]<(measurements[1]*0.58):\r\n","          measurements[5]=measurements[1]*.59\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.56) or measurements[6]<(measurements[1]*.52):\r\n","          measurements[6]=measurements[1]*.54\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.54) or measurements[7]<(measurements[1]*.5):\r\n","          measurements[7]=measurements[1]*.52\r\n","      if (health==\"slim\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.58) or measurements[5]<(measurements[1]*0.54):\r\n","          measurements[5]=measurements[1]*.56\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.54) or measurements[6]<(measurements[1]*.50):\r\n","          measurements[6]=measurements[1]*.52\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.52) or measurements[7]<(measurements[1]*.48):\r\n","          measurements[7]=measurements[1]*.5\r\n","      if (health==\"bulky\"):\r\n","        if measurements[5]==0 or measurements[5]>(measurements[1]*.64) or measurements[5]<(measurements[1]*0.6):\r\n","          measurements[5]=measurements[1]*.62\r\n","        if measurements[6]==0 or measurements[6]>(measurements[1]*.7) or measurements[6]<(measurements[1]*.67):\r\n","          measurements[6]=measurements[1]*.69\r\n","        if measurements[7]==0 or measurements[7]>(measurements[1]*.62) or measurements[7]<(measurements[1]*.59):\r\n","          measurements[7]=measurements[1]*.61\r\n","  print(measurements)\r\n","  return CheckList,measurements \r\n","  "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"G437eopD_p5G","executionInfo":{"status":"ok","timestamp":1608639292821,"user_tz":-300,"elapsed":1114,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["import cv2 as cv\r\n","import numpy as np\r\n","from google.colab.patches import cv2_imshow\r\n","\r\n","BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\r\n","               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7,\"RHip\": 8, \"RKnee\": 9,\r\n","               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\r\n","               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18,\"RBack\" : 19,\"UnderNeck\" :20,\"Waste1\" :21,\"RThigh\":22,\"Waste2\":23,\"RAnkleAbove\":24,\r\n","              \"LBack\":25,\"CentreUpChest\":26,\"Waste3\":27,\"LThigh\":28,\"LToLAnkle\":29,\"LAnkleAbove\":30,\"RToNeck\":31,\"Waste5\":32,\"RChest\":33,\"RElbowAbove\":34,\r\n","              \"RElbowBelow\":35,\"RWristAbove\":36,\"RShoulderAbove\":37,\"Waste6\":38,\"LToNeck\":39,\"Waste7\":40,\"LChest\":41,\"LElbowAbove\":42,\"LElbowBelow\":43,\r\n","              \"LWristAbove\":44,\"LShoulderAbove\":45}\r\n","              \r\n","POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\r\n","               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\r\n","               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\r\n","               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\r\n","               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"],[\"LEye\",\"LAnkle\"],\r\n","               [\"RShoulder\", \"RBack\"],[\"UnderNeck\",\"Neck\"],[\"RKnee\",\"RShoulder\"],[\"LShoulder\",\"LBack\"],[\"Neck\",\"CentreUpChest\"],[\"LKnee\",\"LShoulder\"],\r\n","              [\"LChest\",\"CentreUpChest\"],[\"RHip\",\"LHip\"],[\"RChest\",\"UnderNeck\"],[\"LChest\",\"UnderNeck\"],[\"RChest\",\"CentreUpChest\"]]\r\n","\r\n","width = 368\r\n","height = 368\r\n","inWidth = width\r\n","inHeight = height\r\n","\r\n","net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\r\n","thr = 0.1\r\n","\r\n","def poseDetector(frame):\r\n","    frameWidth = frame.shape[1]\r\n","    frameHeight = frame.shape[0]\r\n","    \r\n","    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\r\n","    out = net.forward()\r\n","    out = out[:, :46, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 46 elements\r\n","\r\n","    assert(len(BODY_PARTS) == out.shape[1])\r\n","\r\n","    points = []\r\n","    point1=[]\r\n","    for i in range(len(BODY_PARTS)):\r\n","        # Slice heatmap of corresponging body's part.\r\n","        heatMap = out[0, i, :, :]\r\n","\r\n","        _, conf, _, point = cv.minMaxLoc(heatMap)\r\n","        x = (frameWidth * point[0]) / out.shape[3]\r\n","        y = (frameHeight * point[1]) / out.shape[2]\r\n","        points.append((int(x),int(y)) if conf > thr else None)\r\n","        point1.append((x,y) if conf > thr else None)\r\n","    print(len(points))\r\n","    for i in range(len(points)):\r\n","      print(i,points[i])\r\n","    for pair in POSE_PAIRS:\r\n","        partFrom = pair[0]\r\n","        partTo = pair[1]\r\n","        assert(partFrom in BODY_PARTS)\r\n","        assert(partTo in BODY_PARTS)\r\n","\r\n","        idFrom = BODY_PARTS[partFrom]\r\n","        idTo = BODY_PARTS[partTo]\r\n","        \r\n","        if points[idFrom] and points[idTo]:\r\n","             cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\r\n","             cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\r\n","             cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\r\n","    i=0\r\n","    for i in range(len(BODY_PARTS)):\r\n","      if( i==23 or i==21 or i==27 or i==32 or i==38 or i==40 or i==28 or i==30 or i==24):\r\n","        cv.ellipse(frame, points[i], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\r\n","      else:\r\n","        cv.ellipse(frame, points[i], (3, 3), 0, 0, 360, (0, 255, 255), cv.FILLED)\r\n","    t, _ = net.getPerfProfile()\r\n","\r\n","    return point1,frame"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcWGmw6yRKOB","executionInfo":{"status":"ok","timestamp":1608639308655,"user_tz":-300,"elapsed":1046,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["import re"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G9yt8J1o5uT","executionInfo":{"status":"ok","timestamp":1608639314537,"user_tz":-300,"elapsed":1164,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}}},"source":["#convert pixels to inches\r\n","def pixelToInches(measurements,height):\r\n","  height=str (height)\r\n","  heightarr=re.split(\"\\.\",height)\r\n","  height=(int(heightarr[0])*12)+int(heightarr[1])\r\n","  print(height)\r\n","  pixelsPerInch=measurements[1]/(height-4)\r\n","  originalmeasurements=[]\r\n","  originalmeasurements.append((measurements[0]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[2]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[3]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[4]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[5]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[6]/pixelsPerInch))\r\n","  originalmeasurements.append((measurements[7]/pixelsPerInch))\r\n","  return originalmeasurements"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNWmzP9U_XCN","executionInfo":{"status":"ok","timestamp":1608640725256,"user_tz":-300,"elapsed":24584,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"8364f1f8-2636-4f5c-e1bf-dc1347b94b2d"},"source":["def mymain():\r\n","  height=input(\"Enter height in feet:\")\r\n","  health=input(\"Are you slim,normal,healthy,bulky:\")\r\n","  gender=input(\"Enter your gender:\")\r\n","  path='/content/drive/My Drive/FYP/zeemal1.mp4'  #video path\r\n","  imagepaths=getFrames(path)\r\n","  CheckList=[False,False,False,False,False,False,False,False] \r\n","  measurements=[0]*len(CheckList)\r\n","  for i in range(len(imagepaths)):\r\n","    input1 = cv.imread(imagepaths[i])\r\n","    frame=i\r\n","    pointsPerFrame,output = poseDetector(input1)\r\n","    CheckList,measurements=GetMeasurementsInPixels(pointsPerFrame,CheckList,measurements,frame,health,gender)\r\n","    print(measurements)\r\n","  if (measurements[1]==0):\r\n","    print(\"kindly make a video again\")\r\n","  originalmeasurements=pixelToInches(measurements,height)\r\n","  print(\"Shoulder to Shoulder\",originalmeasurements[0])\r\n","  print(\"Shirt Length\",originalmeasurements[1])\r\n","  print(\"Shalwar Length\",originalmeasurements[2])\r\n","  print(\"Arm Length\",originalmeasurements[3])\r\n","  print(\"Chest\",originalmeasurements[4])\r\n","  print(\"Waist\",originalmeasurements[5])\r\n","  print(\"UnderChest(Back)\",originalmeasurements[6])\r\n","mymain()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Enter height in feet:4.11\n","Are you slim,normal,healthy,bulky:bulky\n","Enter your gender:female\n","read a new frame: True\n","successful\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","successful\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","successful\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","successful\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","successful\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: True\n","read a new frame: False\n","46\n","0 (516, 250)\n","1 (516, 459)\n","2 (375, 459)\n","3 (305, 667)\n","4 (868, 918)\n","5 (680, 459)\n","6 (751, 667)\n","7 (164, 918)\n","8 (446, 918)\n","9 (586, 1293)\n","10 (586, 1627)\n","11 (610, 918)\n","12 (586, 1293)\n","13 None\n","14 (493, 208)\n","15 (563, 208)\n","16 (446, 250)\n","17 (610, 250)\n","18 (1033, 292)\n","19 None\n","20 (516, 500)\n","21 None\n","22 (446, 1043)\n","23 None\n","24 (586, 1586)\n","25 (540, 542)\n","26 (540, 500)\n","27 None\n","28 (610, 1001)\n","29 None\n","30 (586, 1419)\n","31 None\n","32 None\n","33 None\n","34 (305, 667)\n","35 (845, 876)\n","36 (281, 709)\n","37 (422, 292)\n","38 None\n","39 (540, 459)\n","40 None\n","41 (680, 459)\n","42 (704, 542)\n","43 (751, 709)\n","44 (751, 709)\n","45 None\n","834.782608695652\n","[305.21739130434776, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","[305.21739130434776, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","46\n","0 None\n","1 (727, 1419)\n","2 (540, 375)\n","3 None\n","4 None\n","5 (704, 1460)\n","6 (540, 667)\n","7 (516, 918)\n","8 (563, 960)\n","9 (610, 1252)\n","10 None\n","11 (610, 918)\n","12 (586, 1252)\n","13 None\n","14 None\n","15 None\n","16 None\n","17 (704, 1335)\n","18 (1056, 83)\n","19 None\n","20 (727, 1460)\n","21 (845, 1377)\n","22 (586, 1252)\n","23 (962, 1544)\n","24 (610, 1377)\n","25 (586, 834)\n","26 (586, 876)\n","27 None\n","28 (586, 1043)\n","29 None\n","30 (610, 1419)\n","31 (727, 1419)\n","32 None\n","33 None\n","34 (540, 417)\n","35 None\n","36 None\n","37 None\n","38 None\n","39 (540, 417)\n","40 (704, 1460)\n","41 None\n","42 (540, 626)\n","43 None\n","44 (516, 876)\n","45 None\n","[305.21739130434776, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","[305.21739130434776, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","46\n","0 None\n","1 (610, 417)\n","2 (774, 417)\n","3 (821, 667)\n","4 (892, 918)\n","5 (446, 417)\n","6 (375, 667)\n","7 (258, 918)\n","8 (704, 876)\n","9 (680, 1252)\n","10 None\n","11 (493, 876)\n","12 (563, 1377)\n","13 (234, 918)\n","14 None\n","15 None\n","16 (704, 250)\n","17 (540, 208)\n","18 (0, 0)\n","19 (657, 626)\n","20 (610, 459)\n","21 None\n","22 (680, 1043)\n","23 None\n","24 (680, 1293)\n","25 None\n","26 (610, 417)\n","27 (516, 1085)\n","28 (516, 1085)\n","29 None\n","30 (680, 1460)\n","31 (727, 417)\n","32 None\n","33 (774, 459)\n","34 (821, 667)\n","35 (868, 834)\n","36 (845, 751)\n","37 None\n","38 None\n","39 None\n","40 None\n","41 None\n","42 (399, 584)\n","43 None\n","44 (352, 709)\n","45 (469, 375)\n","[328.695652173913, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","[328.695652173913, 1419.1304347826087, 834.782608695652, 709.5652173913044, 505.420897424983, 788.8695652173911, 755.9999999999999, 657.391304347826]\n","46\n","0 (727, 292)\n","1 (586, 333)\n","2 (633, 333)\n","3 (704, 584)\n","4 (892, 918)\n","5 (610, 292)\n","6 None\n","7 None\n","8 (586, 918)\n","9 (586, 1293)\n","10 None\n","11 (469, 876)\n","12 (586, 1335)\n","13 None\n","14 (727, 250)\n","15 None\n","16 (680, 208)\n","17 None\n","18 (187, 1794)\n","19 None\n","20 (586, 584)\n","21 (563, 918)\n","22 (586, 1085)\n","23 None\n","24 (586, 1335)\n","25 None\n","26 (586, 459)\n","27 None\n","28 (586, 1293)\n","29 None\n","30 (563, 1460)\n","31 (586, 333)\n","32 (610, 375)\n","33 (680, 500)\n","34 (633, 375)\n","35 (774, 709)\n","36 (751, 667)\n","37 (657, 250)\n","38 None\n","39 (657, 333)\n","40 None\n","41 None\n","42 (704, 542)\n","43 None\n","44 None\n","45 None\n","[354.7826086956522, 1419.1304347826087, 808.9043478260869, 780.5217391304349, 454.12173913043483, 879.8608695652174, 979.1999999999999, 865.6695652173913]\n","[354.7826086956522, 1419.1304347826087, 808.9043478260869, 780.5217391304349, 454.12173913043483, 879.8608695652174, 979.1999999999999, 865.6695652173913]\n","46\n","0 (399, 250)\n","1 (422, 375)\n","2 (258, 417)\n","3 (187, 626)\n","4 None\n","5 (563, 417)\n","6 (633, 667)\n","7 (751, 918)\n","8 (328, 918)\n","9 (352, 1377)\n","10 None\n","11 (540, 918)\n","12 (540, 1335)\n","13 (46, 960)\n","14 (375, 208)\n","15 (446, 208)\n","16 (305, 208)\n","17 (493, 208)\n","18 (1033, 417)\n","19 None\n","20 (399, 417)\n","21 None\n","22 (328, 1001)\n","23 None\n","24 (352, 1544)\n","25 (446, 542)\n","26 (422, 417)\n","27 None\n","28 (540, 1001)\n","29 None\n","30 (70, 918)\n","31 None\n","32 None\n","33 None\n","34 (187, 584)\n","35 (751, 876)\n","36 (164, 667)\n","37 (258, 375)\n","38 None\n","39 (422, 375)\n","40 None\n","41 (633, 626)\n","42 (586, 459)\n","43 (657, 709)\n","44 (657, 709)\n","45 None\n","[354.7826086956522, 1419.1304347826087, 808.9043478260869, 780.5217391304349, 454.12173913043483, 879.8608695652174, 979.1999999999999, 865.6695652173913]\n","[354.7826086956522, 1419.1304347826087, 808.9043478260869, 780.5217391304349, 454.12173913043483, 879.8608695652174, 979.1999999999999, 865.6695652173913]\n","59\n","Shoulder to Shoulder 13.75\n","Shirt Length 31.349999999999998\n","Shalwar Length 30.250000000000004\n","Arm Length 17.6\n","Chest 34.1\n","Waist 37.949999999999996\n","UnderChest(Back) 33.55\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ym8XrQTcePLG"},"source":["inp=cv2.imread(imagepaths[0])\r\n","points,output=poseDetector(inp)\r\n","cv2_imshow(output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCx33QwJ_Tpt"},"source":["**Original Measurements**\r\n","\r\n","awais measurements:\r\n","sh to sh = 17.3\r\n","shirt length =39.5\r\n","shalwar length = 36\r\n","sh to wrist =20\r\n","chest = 40\r\n","waist=41\r\n","Back= 35\r\n","\r\n","Feroz measurements:\r\n","sh to sh =17.5\r\n","shirt length =40\r\n","shalwar length=37\r\n","sh to wrist= 23.2\r\n","chest = 37.5\r\n","waist= 36.5\r\n","back=35.7\r\n","\r\n","zeemal measurements:\r\n","sh to sh=13.7\r\n","Shirt Length=31.3\r\n","Shalwar Length=30.3\r\n","Arm Length=17.6\r\n","Chest = 34\r\n","waist = 38\r\n","Back=33.5"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyXysVmotLit","executionInfo":{"status":"ok","timestamp":1608515344239,"user_tz":-300,"elapsed":6008,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"1cbc887b-d46c-49d6-c685-2cbe09bdbf0a"},"source":["!python -m tf_bodypix \\\r\n","    draw-mask \\\r\n","    --source '/content/drive/My Drive/FYP/img1.jpg' \\\r\n","    --output '/content/drive/My Drive/FYP/out3.jpg' \\\r\n","    --threshold=0.5 \\\r\n","    --colored"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/float/050/model-stride16.json\n","\r   8192/Unknown - 0s 0us/stepDownloading data from https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/float/050/group1-shard1of1.bin\n","\r   8192/Unknown - 0s 0us/stepINFO:tf_bodypix.cli:loading model: '/root/.keras/tf-bodypix/8ba301b16e59fd7bda330880a9d70e58-https-storage-googleapis-com-tfjs-models-savedmodel-bodypix-mobilenet-float-050-model-stride16' (downloaded from 'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/float/050/model-stride16.json')\n","INFO:tf_bodypix.sink:writing image to: '/content/drive/My Drive/FYP/out3.jpg'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-vLNmc3V7jD","executionInfo":{"status":"ok","timestamp":1608515840426,"user_tz":-300,"elapsed":4723,"user":{"displayName":"Zainab Aftab","photoUrl":"","userId":"00121570036807087854"}},"outputId":"00683258-0810-445f-db78-0150e9b54061"},"source":["!python -m tf_bodypix \\\r\n","    draw-mask \\\r\n","    --source '/content/drive/My Drive/FYP/imgnext.jpg' \\\r\n","    --output '/content/drive/My Drive/FYP/outnew.jpg' \\\r\n","    --threshold=0.75 \\\r\n","    --parts 'torso_front' 'torso_back'\\\r\n","    --colored"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tf_bodypix.cli:loading model: '/root/.keras/tf-bodypix/8ba301b16e59fd7bda330880a9d70e58-https-storage-googleapis-com-tfjs-models-savedmodel-bodypix-mobilenet-float-050-model-stride16' (downloaded from 'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/float/050/model-stride16.json')\n","INFO:tf_bodypix.sink:writing image to: '/content/drive/My Drive/FYP/outnew.jpg'\n"],"name":"stdout"}]}]}